一：kafka原理
    序1：如何保证数据高可用
        副本（replication）策略
        每个主分区都有多个副本（replication）,这些副本都跟主分区不在同一个broker上，避免broker故障导致数据
        丢失。如果主分区节点故障，会从副本中选举出一个新的主分区。选举时最少三个节点。消费者数据只与主分区
        进行数据交互，副本只是同步主分区的数据而已（类似于主从复制，可以通过配置，实现读写分离）。默认副本
        数量为1个

    1.1：topic
        一个topic里可以有多个partition分区，加快消息生产、消费速度。如果没有指定分区数量，会有一个默认
        的partition分区

    1.2：partition分区
        kafka自动对生产者丢到topic中的消息做了负载均衡，均匀落到各个partition中。也可以指定某个分区



    1.3：Consumer Group(消费组):
        Consumer Group(消费组)是一组Consumer(消费者)的总称.如果只有一组且组内只有一个Consumer,那这个
        就是传统的点对点模式,如果有多组,每组内都有一个Consumer,那这个就是发布-订阅(pub-sub)模式.
        每组都会收到同样的消息.
        注：配置多个组之后，每组都会消费相同消息。也就是所谓的发布订阅模式


二：Producer消息发送问题
    2.1：如何保证数据推送的安全性
        2.1.1：通过设置 acks = all(或者-1)来保证数据都被写入了 leader 分区和副本
            acks = 0 表示producer从来不等待来自broker的确认信息。这个选择提供了最小的时延但同时风险最大
            acks = 1 表示leader partition已经接收了数据的确认信息。这个选择时延较小同时确保了server确认接收成功。
            acks = -1（all）producer会获得所有同步replicas都收到数据的确认。同时时延最大


三：kafka读取数据后，数据是否会自动删除
    不会，kafka的数据删除跟有没有消费者消费完全没有关系。数据的删除只跟kafka broker上面的两个配置有关：
    2.1：log.retention.hours=48               #数据最多保存48小时
    2.2：log.retention.bytes=1073741824       #数据最多1G

四：消费方问题：
    介绍：offset
        offset：指的是kafka的topic中的每个消费组消费的下标。
            简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的
            offset加一那里开始消费。
        比如一个topic中有100条数据，我消费了50条并且提交了，那么此时的kafka服务端记录提交的offset就是49
        (offset从0开始)，那么下次消费的时候offset就从50开始消费。

    4.1：自动提交offset
        生产者发送给Kafka分区的每条消息都有一个偏移量，用于标识每条消息的顺序索引号。要跟踪已处理的消息，
        您的消费者需要提交已处理消息的偏移量。
        除非您手动触发提交，否则您最有可能使用Kafka使用者自动提交机制。自动提交是开箱即用的，默认情况下
        每5秒提交一次。

        注意：自动提交是在kafka拉取到数据之后就直接提交，很容易导致需要进行事务性处理的逻辑异常，数据丢失

        问题：
            4.1.1：消息丢失
                消费方获取1000条消息并将它们缓存到内存中。然后自动提交触发，提交这1000条消息的偏移量。但是，
                假设服务现在使用了太多内存，并且在处理完所有消息之前会被OOM终止信号强行关闭。这样就永远不会
                处理剩余的可能是数百条消息，这就是数据丢失。

            4.1.2:重复消费
                相反的情况，已经成功处理这1000条消息，然后在提交偏移量之前发生问题如硬件故障等。在这种情况
                下，将在消费者重新平衡后重新处理另一个实例上的数百条消息，这就是数据重复。

    4.2:手动提交offset
        配置方式：
            props.put("enable.auto.commit", "false");props.put("max.poll.records", 10);
            需要手动提交的地方只需加上这段代码:
            consumer.commitSync();

   总结；同组内的消费者(单线程消费消息)数量不应多于topic下的partition(分区)数量,不然就会出有消费者空闲
        的状态,此时并发执行的线程数=partition(分区)数量.反之消费者数量少于topic下的partition(分区)数量
        也是不理想的,原因是此时并发执行的线程数=消费者数量,还有的分区没资源去消费。并不能完全发挥kafka
        并发效率.
